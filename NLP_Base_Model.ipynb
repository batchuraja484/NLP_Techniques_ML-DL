{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Model with different approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will follow the below steps to solve this problem\n",
    "<img src=\"ml101-6-step-ml-framework.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to follow\n",
    "1. Problem Definition\n",
    "2. Data\n",
    "3. Evaluation\n",
    "4. Features\n",
    "5. Modeling\n",
    "6. Expermenting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Problem Definition\n",
    "we need to classify the given reviews like postive or negative. Need to get Good Accuracy model for this data. Need to Submit the report in the pi chart format for weekly basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Data \n",
    "Need to disucss with business team and data engineers to know all the sources of this data and try to collect more data. More data you collect your job will be more easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data from tsv file\n",
    "import pandas as pd\n",
    "input_data=pd.read_csv(\"Restaurant_Reviews.tsv\",delimiter=\"\\t\")\n",
    "len(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the duplicate and resetting the index after dropeed the duplicate values\n",
    "input_data.drop_duplicates(inplace=True)\n",
    "input_data=input_data.reset_index(drop=True)\n",
    "len(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluation Metrics\n",
    "as per the customer requirment we need to get 90% accuracy for this model, then only this model will get accepted for prouductionize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Features\n",
    "we need to get the correct features to get the good accuracy score and for text classfication we have some preprocessing steps and after that need to convert the text to vector using \n",
    "1. BOW\n",
    "2. W2V\n",
    "3. TF_IDF\n",
    "4. AvgW2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing Review Data\n",
    "#Removing Duplicates\n",
    "#Remove Special charecters\n",
    "#Converting into lower case\n",
    "#Remove Stop words\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stpwords=stopwords.words('english')\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer=SnowballStemmer('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wow love place', 'crust good', 'tasti textur nasti']\n"
     ]
    }
   ],
   "source": [
    "#Create the corpus of the given data\n",
    "corpus=[]\n",
    "for i in range(0,3):\n",
    "    review=re.sub('[^a-zA-Z]',' ',input_data[\"Review\"][i])\n",
    "    review=review.lower()    \n",
    "    review=review.split()\n",
    "    review=[stemmer.stem(word) for word in review if not word in stpwords]\n",
    "    review=' '.join(review)\n",
    "    corpus.append(review)    \n",
    "\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Applying BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a bag of words model for processing this data\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer()\n",
    "x=cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the lable values into a varaible to pass for train and test data splitting\n",
    "y=input_data[\"Liked\"]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data as train and test sets and need to apply ML model\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Modeling\n",
    "#### 5.1 Applying Gaussina Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying Gaussian Naive Bayes Model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "mdl=GaussianNB()\n",
    "mdl.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict using trained model\n",
    "y_predict=mdl.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[48 48]\n",
      " [17 87]]\n",
      "0.675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.50      0.60        96\n",
      "           1       0.64      0.84      0.73       104\n",
      "\n",
      "    accuracy                           0.68       200\n",
      "   macro avg       0.69      0.67      0.66       200\n",
      "weighted avg       0.69      0.68      0.66       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Verifing the accuracy of this model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cfm=confusion_matrix(y_test,y_predict)\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc_score=accuracy_score(y_test,y_predict)\n",
    "print(cfm)\n",
    "print(acc_score)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stpwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under stood that due to stopwords having (not), some -ve statements were converted into +ve, so we need to create customer stopwords list (exclude the not words from the pouplated list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with non negitive stopwords\n",
    "non_negetive_stopwords=['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself',\n",
    "'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', \n",
    "'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', \n",
    "'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', \n",
    "'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', \n",
    "'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ma', 'won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 179)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(non_negetive_stopwords),len(stpwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Corpus with non negetive stopwords\n",
    "non_neg_corpus=[]\n",
    "for i in range(0,len(input_data)):\n",
    "    review=re.sub('[^a-zA-Z]',' ',input_data[\"Review\"][i])\n",
    "    review=review.lower()\n",
    "    review=review.split()\n",
    "    review=[stemmer.stem(word) for word in review if not word in non_negetive_stopwords]\n",
    "    review=' '.join(review)\n",
    "    non_neg_corpus.append(review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BOW with bi-gram or tri-Gram insted of uni-gram\n",
    "bi_cv=CountVectorizer(ngram_range=(1,2))\n",
    "x_2=bi_cv.fit_transform(non_neg_corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_train,x2_test,y_train,y_test=train_test_split(x_2,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.fit(x2_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_predict=mdl.predict(x2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73\n",
      "[[60 36]\n",
      " [18 86]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.62      0.69        96\n",
      "           1       0.70      0.83      0.76       104\n",
      "\n",
      "    accuracy                           0.73       200\n",
      "   macro avg       0.74      0.73      0.73       200\n",
      "weighted avg       0.74      0.73      0.73       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Verifying the accuracy of the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "acc_score_2=accuracy_score(y_test,y2_predict)\n",
    "print(acc_score_2)\n",
    "print(confusion_matrix(y_test,y2_predict))\n",
    "print(classification_report(y_test,y2_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BOW with trigram\n",
    "tri_cv=CountVectorizer(ngram_range=(1,3))\n",
    "x3=tri_cv.fit_transform(non_neg_corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the converted data into Train and Test Data Sets\n",
    "x3_train,x3_test,y_train,y_test=train_test_split(x3,y,test_size=0.2,random_state=42)\n",
    "mdl.fit(x3_train,y_train)\n",
    "y3_predict=mdl.predict(x3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.725\n",
      "[[60 36]\n",
      " [19 85]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.62      0.69        96\n",
      "           1       0.70      0.82      0.76       104\n",
      "\n",
      "    accuracy                           0.73       200\n",
      "   macro avg       0.73      0.72      0.72       200\n",
      "weighted avg       0.73      0.72      0.72       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model performance\n",
    "x3_acc=accuracy_score(y_test,y3_predict)\n",
    "print(x3_acc)\n",
    "print(confusion_matrix(y_test,y3_predict))\n",
    "print(classification_report(y_test,y3_predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
